# -*- coding: utf-8 -*-
"""inference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M6sK247yvK9IZWYKdoicEgMGJ9jXc6Y_
"""

import argparse
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

def load_model_and_tokenizer(model_path, device):
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)
    model.to(device)
    model.eval()
    return tokenizer, model

def with_prompt(review):
    return (
        "Extract all aspect-category-opinion-sentiment quadruples from the following review. "
        "Format each as: aspect##category##opinion##sentiment. Use [SSEP] to separate multiple quads.\n\n"
        + review.strip()
    )
def predict_acos(review, model, tokenizer, device):
    prompt = with_prompt(review)
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True).to(device)
    outputs = model.generate(**inputs, max_new_tokens=128)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

def run_inference(input_csv, output_csv, model_path):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    tokenizer, model = load_model_and_tokenizer(model_path, device)

    df = pd.read_csv(input_csv)
    predictions = []

    for review in df["Review Text"]:
        prediction = predict_acos(review, model, tokenizer, device)
        predictions.append(prediction)

    df["predicted_quads"] = predictions
    df.to_csv(output_csv, index=False)
    print(f"Results saved to: {output_csv}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run ACOSQE inference using a fine-tuned T5 model.")
    parser.add_argument("--input_csv", required=True, help="Path to input .csv file with 'review' column")
    parser.add_argument("--output_csv", required=True, help="Path to output .csv file")
    parser.add_argument("--model_path", default="models/v4.1", help="Path to trained model directory")
    args = parser.parse_args()

    run_inference(args.input_csv, args.output_csv, args.model_path)